{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Kaggle Competition V3\n",
    "\n",
    "#### Predict the survivors of the Titanic disaster given personal information. Key predictor variables are the age, gender, family size, title, embarkment location, passenger class, and fare price paid by the passenger. The predicted variable is a binary survival/not survival of the passenger.\n",
    "\n",
    "#### The train.csv file provides the data for training the model predictions and the test.csv provides the data for testing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following notebook is organized as follows:\n",
    "#### 1. Library imports and file imports\n",
    "#### 2. EDA \n",
    "#### 3. Feature Creation \n",
    "#### 4. Missing Values Resolution\n",
    "#### 5. Model Training\n",
    "#### 6. Model Testing\n",
    "#### 7. Model Validation on Test Data Provided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library imports and file imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly as plt\n",
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "\n",
    "train_df = pd.read_csv(r'train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The SibSp and Parch values may be of interest in combining for another data set given advice from sources online. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "-------------COMPARISON OF TRAIN (ABOVE) AND TEST DATA (BELOW)------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()\n",
    "\n",
    "print(\"-------------COMPARISON OF TRAIN (ABOVE) AND TEST DATA (BELOW)------------\")\n",
    "\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name, Sex, Cabin, Embarked will have to be converted to encoded categorical data if usable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n",
       "       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n",
       "       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n",
       "       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n",
       "       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n",
       "       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n",
       "       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n",
       "       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n",
       "       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n",
       "       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n",
       "       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n",
       "       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n",
       "       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n",
       "       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n",
       "       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n",
       "       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n",
       "       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n",
       "       'C148'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Cabin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'Age', 'Cabin' and 'Emabarked' (almost none) data sets are missing data that will have to be accounted for. I believe that multiple imputation may be best for 'Age', while 'Cabin' may be unusbale given the eratic nature of the labels (possibler to pull decks from cabins??), and using something like mode may be easiest for 'Embarked' data given that there are very few missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the survived target variable we can see the outcome of our classification model should predict something in the neighborhood of 62% died and 38% survivors for our test data, assuming a equally-representable sample was taken for test and training data sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PClass Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Passenger Class data set: [3 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Found a useful groupby function online for quick comparisons and examples on Titanic data set from Kaggle user ZlatanKremonic\n",
    "\n",
    "print(\"Unique values in Passenger Class data set:\", train_df.Pclass.unique())\n",
    "\n",
    "train_df['Survived'].groupby(train_df['Pclass']).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the Passenger Classes were postively correlated to the survival rate. We will treat Passenger class as a categorical variable with no adjustments given no null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Titles of the passengers to see the usefulness of the new variable. This is done frequently by others online and the length of the name is also used to compare with survival rate online. Some used the test set to combine data and gain additional titles/name lengths, but attempting to keep this process at least somewhat representative of a \"real world\" applicaiton, in which a test set would not be used to train the model at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Title'] = train_df['Name'].str.split(r'[,.]').str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       " Capt            0.000000\n",
       " Col             0.500000\n",
       " Don             0.000000\n",
       " Dr              0.428571\n",
       " Jonkheer        0.000000\n",
       " Lady            1.000000\n",
       " Major           0.500000\n",
       " Master          0.575000\n",
       " Miss            0.697802\n",
       " Mlle            1.000000\n",
       " Mme             1.000000\n",
       " Mr              0.156673\n",
       " Mrs             0.792000\n",
       " Ms              1.000000\n",
       " Rev             0.000000\n",
       " Sir             1.000000\n",
       " the Countess    1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Survived.groupby(train_df.Title).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given that the actual survival rate of men vs women on the titanic was Men: 20% Women:80%, this title variable matches real world expectations closely, and the higher survvial rates for \"wealthier sounding\" titles may be more helpful to differentiate target variable instead of just Gender variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get name length and check if it correlates to survival rate\n",
    "\n",
    "train_df['Name_Length'] = train_df.Name.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19    64\n",
       "25    55\n",
       "27    50\n",
       "18    50\n",
       "26    49\n",
       "28    43\n",
       "24    43\n",
       "17    42\n",
       "21    40\n",
       "23    39\n",
       "20    39\n",
       "22    38\n",
       "30    37\n",
       "29    32\n",
       "31    30\n",
       "16    26\n",
       "32    23\n",
       "33    22\n",
       "15    15\n",
       "47    11\n",
       "37    10\n",
       "38     9\n",
       "36     9\n",
       "39     9\n",
       "45     9\n",
       "44     8\n",
       "41     8\n",
       "34     7\n",
       "46     7\n",
       "40     7\n",
       "51     7\n",
       "35     6\n",
       "43     5\n",
       "42     5\n",
       "49     5\n",
       "50     4\n",
       "52     4\n",
       "56     3\n",
       "14     3\n",
       "48     3\n",
       "13     2\n",
       "12     2\n",
       "53     2\n",
       "55     2\n",
       "57     2\n",
       "67     1\n",
       "54     1\n",
       "61     1\n",
       "65     1\n",
       "82     1\n",
       "Name: Name_Length, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Name_Length.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name_Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>308</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Penasco y Castellana, Mrs. Victor de Satode (M...</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9</td>\n",
       "      <td>C65</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "307          308         1       1   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "307  Penasco y Castellana, Mrs. Victor de Satode (M...  female  17.0      1   \n",
       "\n",
       "     Parch    Ticket   Fare Cabin Embarked Title  Name_Length  \n",
       "307      0  PC 17758  108.9   C65        C   Mrs           82  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking possible error in longest name at 82 characters, seems like a married spanish surname combination, OK\n",
    "train_df.loc[train_df['Name_Length'] == 82]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the Name Lengths in quarteriles to check correlation to Survival rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_Length\n",
       "(11.999, 20.0]    0.230453\n",
       "(20.0, 25.0]      0.325581\n",
       "(25.0, 30.0]      0.364929\n",
       "(30.0, 82.0]      0.626126\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(pd.qcut(train_df['Name_Length'],4)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.999, 20.0]    243\n",
       "(30.0, 82.0]      222\n",
       "(20.0, 25.0]      215\n",
       "(25.0, 30.0]      211\n",
       "Name: Name_Length, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train_df['Name_Length'],4).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the gender data in comparison to average survival rate, this will be used as categorical variable and encoded later. We already konw from dataframe info that there are no nulls that need to be dealt with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      577\n",
       "female    314\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Sex.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    0.742038\n",
       "male      0.188908\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(train_df['Sex']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From our work with titles and online research we can see that the train set of data has a slightly lower average survival rate for females and slightly lower average survival rate for females than the gender survival rate of the actual Titanic event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will have to address the large number of missing values in the Age variable. I believe that using multiple imputation by chained equations may be the most accurate given we have a large number other data variables that we can use to iterate through in order to arrive at the \"best guess\" age given the passenger's other data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "(0.419, 9.0]      0.612903\n",
       "(9.0, 18.0]       0.415584\n",
       "(18.0, 20.125]    0.300000\n",
       "(20.125, 23.0]    0.313433\n",
       "(23.0, 25.0]      0.381818\n",
       "(25.0, 28.0]      0.393443\n",
       "(28.0, 31.0]      0.393939\n",
       "(31.0, 34.0]      0.440000\n",
       "(34.0, 38.0]      0.474576\n",
       "(38.0, 44.0]      0.370968\n",
       "(44.0, 51.0]      0.396552\n",
       "(51.0, 80.0]      0.350877\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(pd.qcut(train_df['Age'],12)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see that the relationship between survival and age is far more positive for passengers under the age of 9. It is fairly even though for other ages when compared to the survival rate. It is also clear that the average survival rate was higher for passengers between the ages of 31 and 38."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SibSp and Parch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp\n",
       "0    0.345395\n",
       "1    0.535885\n",
       "2    0.464286\n",
       "3    0.250000\n",
       "4    0.166667\n",
       "5    0.000000\n",
       "8    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(train_df['SibSp']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given that there is not a clear correlation between the SibSp variable and survival, we can look at combining the variables (SibSp and Parch) to see if it correlates well to survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fam_Size'] = train_df.SibSp + train_df.Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fam_Size\n",
       "0     0.303538\n",
       "1     0.552795\n",
       "2     0.578431\n",
       "3     0.724138\n",
       "4     0.200000\n",
       "5     0.136364\n",
       "6     0.333333\n",
       "7     0.000000\n",
       "10    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(train_df['Fam_Size']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the grouping of average survivors and the family size, we can see that the combination of the two variables (Parents and childs and Siblings and Spouses) seems to have a higher correlation to the average rate of survival given that the family size was zero to three, while anything over that was not significant (other than a family size of 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     537\n",
       "1     161\n",
       "2     102\n",
       "3      29\n",
       "5      22\n",
       "4      15\n",
       "6      12\n",
       "10      7\n",
       "7       6\n",
       "Name: Fam_Size, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Fam_Size.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ticket Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           A/5 21171\n",
       "1            PC 17599\n",
       "2    STON/O2. 3101282\n",
       "3              113803\n",
       "4              373450\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Ticket.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering the variability in the ticket variable, it may not be worth applying without changes. Given the online sources they do reference the correlation between ticket string length and survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_Length'] = train_df.Ticket.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket_Length\n",
       "3     0.000000\n",
       "4     0.366337\n",
       "5     0.618321\n",
       "6     0.319809\n",
       "7     0.296296\n",
       "8     0.539474\n",
       "9     0.192308\n",
       "10    0.341463\n",
       "11    0.250000\n",
       "12    0.400000\n",
       "13    0.400000\n",
       "15    0.333333\n",
       "16    0.272727\n",
       "17    0.428571\n",
       "18    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Survived.groupby(train_df.Ticket_Length).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the grouping we can see that the average survival rate was far better for some than others given the length of the ticket name. This may be due to the locations that the tickes were bought, and therefore had higher instances of women or children from one location adn therefore a different ticket name length. Or the instance of eight characters in the ticket versus a ticket with a name length of 9 may reflect a ticket namig schema the Titanic parent company used for higher decks of the ship versus lower decks of the ship, thus giving us a higher survival rate for some lengths and not others. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will explore whether or not the inclusion any letter or special characters in the ticket string have significance in the survival of the passenger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           A/5 21171\n",
       "1            PC 17599\n",
       "2    STON/O2. 3101282\n",
       "3              113803\n",
       "4              373450\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Ticket.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isdigit on column of Tickets to see True/False of whether or not they are only digits\n",
    "\n",
    "train_df['Ticket_Char'] = train_df['Ticket'].str.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert True False from .isdigit() to integers\n",
    "\n",
    "train_df['Ticket_Char'] = train_df.Ticket_Char.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket_Char\n",
       "0    0.382609\n",
       "1    0.384266\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to see the correlation between the tickets with only digits and survival rate\n",
    "\n",
    "train_df['Survived'].groupby(train_df['Ticket_Char']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the grouped results above we can see that there was not a meaningful difference in average survival rate of passengers with tickets with solely digits vs tickets with characters. I will keep the variable in the data set in case the Random Forest can include it at a deep level of the decision tree and may aid in further classification of the target variable. (this logic seen online and applied here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will take the first letter of each ticket as well to see if this provides us any insight to survival. Online sources used this is an exmaple for more meaningful extraction from ticket variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Ticket_First_Char'] = train_df.Ticket.astype(str).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3    301\n",
      "2    183\n",
      "1    146\n",
      "S     65\n",
      "P     65\n",
      "C     47\n",
      "A     29\n",
      "W     13\n",
      "4     10\n",
      "7      9\n",
      "F      7\n",
      "6      6\n",
      "L      4\n",
      "5      3\n",
      "8      2\n",
      "9      1\n",
      "Name: Ticket_First_Char, dtype: int64\n",
      "--------------------------------------\n",
      "Ticket_First_Char\n",
      "1    0.630137\n",
      "2    0.464481\n",
      "3    0.239203\n",
      "4    0.200000\n",
      "5    0.000000\n",
      "6    0.166667\n",
      "7    0.111111\n",
      "8    0.000000\n",
      "9    1.000000\n",
      "A    0.068966\n",
      "C    0.340426\n",
      "F    0.571429\n",
      "L    0.250000\n",
      "P    0.646154\n",
      "S    0.323077\n",
      "W    0.153846\n",
      "Name: Survived, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train_df['Ticket_First_Char'].value_counts())\n",
    "\n",
    "print('--------------------------------------')\n",
    "\n",
    "print(train_df['Survived'].groupby(train_df['Ticket_First_Char']).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the grouping above we can see that tickets with a first character 'C' were much more likely to survive versus a ticket with a first character of 'W'. This may be due to PAssenger Class or even embarkment locaiton, but gives us another variable to use in the random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will look at the fare price relative to the average survival rate of passengers. From the quick correlation ran below, we can see this will be positively correlated to a higher rate of survival. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare\n",
       "(-0.001, 7.854]      0.217877\n",
       "(7.854, 10.5]        0.201087\n",
       "(10.5, 21.679]       0.424419\n",
       "(21.679, 39.688]     0.444444\n",
       "(39.688, 512.329]    0.642045\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(pd.qcut(train_df['Fare'],5)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above we can see that the 5th quantile with highest ticket prices had a far better average survival rate than that of passengers who paid the lowest fares. If passengers who paid lower fares were indeed in the bottom decks of the ship at the time of the incident, then it would make sense that they would be more likely to have not survived. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabin Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the large amount of data mising from the Cabin variable, and that when we quickly looked at the Cabin data previously and saw extreme differences in the strings of the cabin assignments, we will have to explore the data further to glean usable data from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'C85', 'C123', 'E46', 'G6', 'C103', 'D56', 'A6',\n",
       "       'C23 C25 C27', 'B78', 'D33', 'B30', 'C52', 'B28', 'C83', 'F33',\n",
       "       'F G73', 'E31', 'A5', 'D10 D12', 'D26', 'C110', 'B58 B60', 'E101',\n",
       "       'F E69', 'D47', 'B86', 'F2', 'C2', 'E33', 'B19', 'A7', 'C49', 'F4',\n",
       "       'A32', 'B4', 'B80', 'A31', 'D36', 'D15', 'C93', 'C78', 'D35',\n",
       "       'C87', 'B77', 'E67', 'B94', 'C125', 'C99', 'C118', 'D7', 'A19',\n",
       "       'B49', 'D', 'C22 C26', 'C106', 'C65', 'E36', 'C54',\n",
       "       'B57 B59 B63 B66', 'C7', 'E34', 'C32', 'B18', 'C124', 'C91', 'E40',\n",
       "       'T', 'C128', 'D37', 'B35', 'E50', 'C82', 'B96 B98', 'E10', 'E44',\n",
       "       'A34', 'C104', 'C111', 'C92', 'E38', 'D21', 'E12', 'E63', 'A14',\n",
       "       'B37', 'C30', 'D20', 'B79', 'E25', 'D46', 'B73', 'C95', 'B38',\n",
       "       'B39', 'B22', 'C86', 'C70', 'A16', 'C101', 'C68', 'A10', 'E68',\n",
       "       'B41', 'A20', 'D19', 'D50', 'D9', 'A23', 'B50', 'A26', 'D48',\n",
       "       'E58', 'C126', 'B71', 'B51 B53 B55', 'D49', 'B5', 'B20', 'F G63',\n",
       "       'C62 C64', 'E24', 'C90', 'C45', 'E8', 'B101', 'D45', 'C46', 'D30',\n",
       "       'E121', 'D11', 'E77', 'F38', 'B3', 'D6', 'B82 B84', 'D17', 'A36',\n",
       "       'B102', 'B69', 'E49', 'C47', 'D28', 'E17', 'A24', 'C50', 'B42',\n",
       "       'C148'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore Cabin Data\n",
    "\n",
    "train_df.Cabin.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The cabin letters are most likely Deck assignments and may be useful for us to use. We will split the Cabin strings and then use the letters as well as the cabin numbers to see if they tell us anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the strings to take the first character as the deck assignment and the second, third and fourth characters as the cabin numbers.\n",
    "\n",
    "train_df['Cabin_Deck'] = train_df.Cabin.astype(str).str[0]\n",
    "train_df['Cabin_Deck'].replace('n',np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_Deck\n",
       "A    0.466667\n",
       "B    0.744681\n",
       "C    0.593220\n",
       "D    0.757576\n",
       "E    0.750000\n",
       "F    0.615385\n",
       "G    0.500000\n",
       "T    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(train_df['Cabin_Deck']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above we can see that the passengers with cabins on Decks (an assumption that was verified online) 'B', 'D', 'E' were much more likely to survive than passengers on Decks 'A' or 'G'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '85', '123', '46', '6', '103', '56', '23 C25 C27', '78', '33',\n",
       "       '30', '52', '28', '83', ' G73', '31', '5', '10 D12', '26', '110',\n",
       "       '58 B60', '101', ' E69', '47', '86', '2', '19', '7', '49', '4',\n",
       "       '32', '80', '36', '15', '93', '35', '87', '77', '67', '94', '125',\n",
       "       '99', '118', '', '22 C26', '106', '65', '54', '57 B59 B63 B66',\n",
       "       '34', '18', '124', '91', '40', '128', '37', '50', '82', '96 B98',\n",
       "       '10', '44', '104', '111', '92', '38', '21', '12', '63', '14', '20',\n",
       "       '79', '25', '73', '95', '39', '22', '70', '16', '68', '41', '9',\n",
       "       '23', '48', '58', '126', '71', '51 B53 B55', ' G63', '62 C64',\n",
       "       '24', '90', '45', '8', '121', '11', '3', '82 B84', '17', '102',\n",
       "       '69', '42', '148'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Cabin_Number'] = train_df.Cabin.astype(str).str[1:]\n",
    "train_df['Cabin_Number'].replace('an',np.NaN,inplace=True)\n",
    "train_df['Cabin_Number'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with irregular additional cabins lumped together, splitting string to take only first cabin number of string, and converting to integer\n",
    "\n",
    "train_df['Cabin_Number'] = train_df['Cabin_Number'].str.split(' ').str[0]\n",
    "\n",
    "train_df['Cabin_Number'] = pd.to_numeric(train_df['Cabin_Number'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_Number\n",
       "(1.999, 11.857]     0.714286\n",
       "(11.857, 23.714]    0.714286\n",
       "(23.714, 35.0]      0.741935\n",
       "(35.0, 49.0]        0.607143\n",
       "(49.0, 69.286]      0.680000\n",
       "(69.286, 96.0]      0.612903\n",
       "(96.0, 148.0]       0.680000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking groupby of survived and cabin numbers\n",
    "\n",
    "train_df['Survived'].groupby(pd.qcut(train_df['Cabin_Number'],7)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the above values we can see some differentiation in the average survival rate of passengers given certain groups of Cabin Numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embarked Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at the port of embarkment, we can see at a quick glance that a passenger that departed from port C had a higher average rate of survival than a passenger who departed from port Q or S. This may be due to the areas of departure may have had more females or higher class passengers than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C    0.553571\n",
       "Q    0.389610\n",
       "S    0.336957\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Survived'].groupby(train_df['Embarked']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Embarked.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given that there are only two missing values, we will use the port that occurs the most to fill in the missing values later on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding categorical data BEFORE imputation section next. This ensures better regression estimates instead of using only current numerical values. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After research online settled on dummies function in pandas for categorical encoding. It will create a larger dataset but will test to see if it creates a problem with the random forest computation times. Ideally it would be worth looking at multiple encoding options and model types to use in conjunction for an average rate of survival on the test set (shown by user 'Volha' on Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEED TO LOOK AT MICE IMPUTER THAT CAN AUTO CREATE BINARY COLUMNS OF MISSing VLAUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Added columns to identify missing data points in variables\n",
    "#Age\n",
    "train_df['Age_missing'] = (~train_df['Age'].isnull()).astype(int)\n",
    "\n",
    "#Embarked\n",
    "train_df['Embarked_missing'] = (~train_df['Embarked'].isnull()).astype(int)\n",
    "\n",
    "#Cabin_Deck\n",
    "train_df['Cabin_Deck_missing'] = (~train_df['Cabin_Deck'].isnull()).astype(int)\n",
    "\n",
    "#Cabin_Number\n",
    "train_df['Cabin_Number_missing'] = (~train_df['Cabin_Number'].isnull()).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Will need to encode: 'PClass', 'Sex', 'Embarked', 'Title', 'Ticket_First_Char', 'Cabin_Deck'.\n",
    "#### I am not going back to encode FamSize into a group and therefore have an ordinal data set since the size of the family is important in label, and not use the dummies encoding for 'FamSize', 'Age', or 'Fare'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_First_Char_P</th>\n",
       "      <th>Ticket_First_Char_S</th>\n",
       "      <th>Ticket_First_Char_W</th>\n",
       "      <th>Cabin_Deck_B</th>\n",
       "      <th>Cabin_Deck_C</th>\n",
       "      <th>Cabin_Deck_D</th>\n",
       "      <th>Cabin_Deck_E</th>\n",
       "      <th>Cabin_Deck_F</th>\n",
       "      <th>Cabin_Deck_G</th>\n",
       "      <th>Cabin_Deck_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Name_Length  ...  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN           23  ...   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85           51  ...   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN           22  ...   \n",
       "3  35.0      1      0            113803  53.1000  C123           44  ...   \n",
       "4  35.0      0      0            373450   8.0500   NaN           24  ...   \n",
       "\n",
       "   Ticket_First_Char_P  Ticket_First_Char_S  Ticket_First_Char_W  \\\n",
       "0                    0                    0                    0   \n",
       "1                    1                    0                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   Cabin_Deck_B  Cabin_Deck_C  Cabin_Deck_D  Cabin_Deck_E  Cabin_Deck_F  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             1             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             1             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   Cabin_Deck_G  Cabin_Deck_T  \n",
       "0             0             0  \n",
       "1             0             0  \n",
       "2             0             0  \n",
       "3             0             0  \n",
       "4             0             0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the dummies funstion on the train_df  nominal categorical data variables. \n",
    "\n",
    "train_df = pd.get_dummies(train_df, columns = ['Pclass', 'Sex', 'Embarked', 'Title', 'Ticket_First_Char', 'Cabin_Deck'],prefix_sep='_', drop_first = True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Need to drop the columns we are not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop PassengerID, Name, Ticket, Cabin columns\n",
    "\n",
    "train_df = train_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Missing Value Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived                  0\n",
       "Age                     177\n",
       "SibSp                     0\n",
       "Parch                     0\n",
       "Fare                      0\n",
       "Name_Length               0\n",
       "Fam_Size                  0\n",
       "Ticket_Length             0\n",
       "Ticket_Char               0\n",
       "Cabin_Number            695\n",
       "Age_missing               0\n",
       "Embarked_missing          0\n",
       "Cabin_Deck_missing        0\n",
       "Cabin_Number_missing      0\n",
       "Pclass_2                  0\n",
       "Pclass_3                  0\n",
       "Sex_male                  0\n",
       "Embarked_Q                0\n",
       "Embarked_S                0\n",
       "Title_ Col                0\n",
       "Title_ Don                0\n",
       "Title_ Dr                 0\n",
       "Title_ Jonkheer           0\n",
       "Title_ Lady               0\n",
       "Title_ Major              0\n",
       "Title_ Master             0\n",
       "Title_ Miss               0\n",
       "Title_ Mlle               0\n",
       "Title_ Mme                0\n",
       "Title_ Mr                 0\n",
       "Title_ Mrs                0\n",
       "Title_ Ms                 0\n",
       "Title_ Rev                0\n",
       "Title_ Sir                0\n",
       "Title_ the Countess       0\n",
       "Ticket_First_Char_2       0\n",
       "Ticket_First_Char_3       0\n",
       "Ticket_First_Char_4       0\n",
       "Ticket_First_Char_5       0\n",
       "Ticket_First_Char_6       0\n",
       "Ticket_First_Char_7       0\n",
       "Ticket_First_Char_8       0\n",
       "Ticket_First_Char_9       0\n",
       "Ticket_First_Char_A       0\n",
       "Ticket_First_Char_C       0\n",
       "Ticket_First_Char_F       0\n",
       "Ticket_First_Char_L       0\n",
       "Ticket_First_Char_P       0\n",
       "Ticket_First_Char_S       0\n",
       "Ticket_First_Char_W       0\n",
       "Cabin_Deck_B              0\n",
       "Cabin_Deck_C              0\n",
       "Cabin_Deck_D              0\n",
       "Cabin_Deck_E              0\n",
       "Cabin_Deck_F              0\n",
       "Cabin_Deck_G              0\n",
       "Cabin_Deck_T              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check sum of nulls in data\n",
    "\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the list of nulls above we will deal with the missing data in the following ways:\n",
    "\n",
    "### Age: \n",
    "#### MICE: This appears to be an important variable, given that we previously identified passengers under the age of 9 were far more likely to survive than others, multiple imputation chained equations (MICE) may be the best choice to provide a better estimated missing value if other young passengers can be \"identified\" given the other variables in the data. \n",
    "\n",
    "### Cabin_Number: \n",
    "#### Imputation using MICE as well, I will look at using these varaibles in Random Forest and without, to see if results improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and Cabin_Number Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import mice and apply\n",
    "from fancyimpute import IterativeImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(random_state=42)\n",
    "\n",
    "train_df_imputed = pd.DataFrame(imputer.fit_transform(train_df), columns = train_df.columns)\n",
    "\n",
    "train_df = train_df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Test Train sets for Survived column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Fam_Size</th>\n",
       "      <th>Ticket_Length</th>\n",
       "      <th>Ticket_Char</th>\n",
       "      <th>Cabin_Number</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_First_Char_P</th>\n",
       "      <th>Ticket_First_Char_S</th>\n",
       "      <th>Ticket_First_Char_W</th>\n",
       "      <th>Cabin_Deck_B</th>\n",
       "      <th>Cabin_Deck_C</th>\n",
       "      <th>Cabin_Deck_D</th>\n",
       "      <th>Cabin_Deck_E</th>\n",
       "      <th>Cabin_Deck_F</th>\n",
       "      <th>Cabin_Deck_G</th>\n",
       "      <th>Cabin_Deck_T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>29.671070</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>26.965208</td>\n",
       "      <td>0.904602</td>\n",
       "      <td>6.750842</td>\n",
       "      <td>0.741863</td>\n",
       "      <td>49.976140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072952</td>\n",
       "      <td>0.072952</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.052750</td>\n",
       "      <td>0.066218</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.035915</td>\n",
       "      <td>0.014590</td>\n",
       "      <td>0.004489</td>\n",
       "      <td>0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>13.647529</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>9.281607</td>\n",
       "      <td>1.613459</td>\n",
       "      <td>2.745515</td>\n",
       "      <td>0.437855</td>\n",
       "      <td>16.685253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260203</td>\n",
       "      <td>0.260203</td>\n",
       "      <td>0.119973</td>\n",
       "      <td>0.223659</td>\n",
       "      <td>0.248802</td>\n",
       "      <td>0.188959</td>\n",
       "      <td>0.186182</td>\n",
       "      <td>0.119973</td>\n",
       "      <td>0.066890</td>\n",
       "      <td>0.033501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.151650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.908437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.919823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.952271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived         Age       SibSp       Parch        Fare  \\\n",
       "count  891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean     0.383838   29.671070    0.523008    0.381594   32.204208   \n",
       "std      0.486592   13.647529    1.102743    0.806057   49.693429   \n",
       "min      0.000000   -7.151650    0.000000    0.000000    0.000000   \n",
       "25%      0.000000   21.000000    0.000000    0.000000    7.910400   \n",
       "50%      0.000000   29.000000    0.000000    0.000000   14.454200   \n",
       "75%      1.000000   36.750000    1.000000    0.000000   31.000000   \n",
       "max      1.000000   80.000000    8.000000    6.000000  512.329200   \n",
       "\n",
       "       Name_Length    Fam_Size  Ticket_Length  Ticket_Char  Cabin_Number  ...  \\\n",
       "count   891.000000  891.000000     891.000000   891.000000    891.000000  ...   \n",
       "mean     26.965208    0.904602       6.750842     0.741863     49.976140  ...   \n",
       "std       9.281607    1.613459       2.745515     0.437855     16.685253  ...   \n",
       "min      12.000000    0.000000       3.000000     0.000000      2.000000  ...   \n",
       "25%      20.000000    0.000000       5.000000     0.000000     49.908437  ...   \n",
       "50%      25.000000    0.000000       6.000000     1.000000     49.919823  ...   \n",
       "75%      30.000000    1.000000       7.000000     1.000000     49.952271  ...   \n",
       "max      82.000000   10.000000      18.000000     1.000000    148.000000  ...   \n",
       "\n",
       "       Ticket_First_Char_P  Ticket_First_Char_S  Ticket_First_Char_W  \\\n",
       "count           891.000000           891.000000           891.000000   \n",
       "mean              0.072952             0.072952             0.014590   \n",
       "std               0.260203             0.260203             0.119973   \n",
       "min               0.000000             0.000000             0.000000   \n",
       "25%               0.000000             0.000000             0.000000   \n",
       "50%               0.000000             0.000000             0.000000   \n",
       "75%               0.000000             0.000000             0.000000   \n",
       "max               1.000000             1.000000             1.000000   \n",
       "\n",
       "       Cabin_Deck_B  Cabin_Deck_C  Cabin_Deck_D  Cabin_Deck_E  Cabin_Deck_F  \\\n",
       "count    891.000000    891.000000    891.000000    891.000000    891.000000   \n",
       "mean       0.052750      0.066218      0.037037      0.035915      0.014590   \n",
       "std        0.223659      0.248802      0.188959      0.186182      0.119973   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       Cabin_Deck_G  Cabin_Deck_T  \n",
       "count    891.000000    891.000000  \n",
       "mean       0.004489      0.001122  \n",
       "std        0.066890      0.033501  \n",
       "min        0.000000      0.000000  \n",
       "25%        0.000000      0.000000  \n",
       "50%        0.000000      0.000000  \n",
       "75%        0.000000      0.000000  \n",
       "max        1.000000      1.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the labels ('Survived') from the dataset and drop unnecessary PassenengerID column. ALWAYS SPLIT DATA BEFORE NORMALIZATION TO AVOID DATA LEAKAGE (outside influences on train data)\n",
    "\n",
    "X = train_df.drop(columns=['Survived'])\n",
    "y = train_df['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test Split (set random state to 42 for answer to the universe)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=42)\n",
    "\n",
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "#### I will look at obtaining the best parameters for the random forest classifer using a grid search. I will look at improving computation time by possibly using a GPU later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import grid search and classifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid\n",
    "# param_grid = {\"max_depth\" : [10, 20, 30, 40, 50],\n",
    "#              \"criterion\" : [\"gini\", \"entropy\"],\n",
    "#              \"min_samples_leaf\" : [1,2,3],\n",
    "#              \"min_samples_split\" : [2, 3, 4, 5, 6],\n",
    "#              \"n_estimators\": [50,75, 100, 125, 150, 200]}\n",
    "\n",
    "\n",
    "# # Create a Random Forest model\n",
    "# rf = RandomForestClassifier(max_features = 'auto', oob_score = True, random_state = 42, n_jobs=-1)\n",
    "\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the grid search to the data\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Given the above we will fit the best parameters to a rf model and also test a generic untuned model to see the differences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit paramters from grid search\n",
    "#best parameters 1 = {'criterion': 'entropy', 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 75}\n",
    "\n",
    "\n",
    "rf_base = RandomForestClassifier(oob_score = True, random_state = 42, n_jobs=-1)\n",
    "rf_best = RandomForestClassifier(criterion = 'entropy', max_depth = 10, min_samples_leaf = 1, min_samples_split = 2, n_estimators = 75, max_features = 'auto', oob_score = True, random_state = 42, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed classification report:Base RF Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.88      0.87       105\n",
      "         1.0       0.82      0.81      0.82        74\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.84      0.84      0.84       179\n",
      "weighted avg       0.85      0.85      0.85       179\n",
      "\n",
      "0.8258426966292135\n",
      "========================================================================================================\n",
      "Detailed classification report: Best Paramaters 1st Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.90      0.88       105\n",
      "         1.0       0.84      0.80      0.82        74\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.85      0.85      0.85       179\n",
      "weighted avg       0.85      0.85      0.85       179\n",
      "\n",
      "0.8300561797752809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Fit best model and test base results and compare the two results\n",
    "#base\n",
    "rf_base.fit(X_train, y_train)\n",
    "\n",
    "print(\"Detailed classification report:Base RF Model\")\n",
    "y_base_pred = rf_base.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_base_pred))\n",
    "\n",
    "print(rf_base.oob_score_)\n",
    "\n",
    "print('========================================================================================================')\n",
    "\n",
    "#best 1\n",
    "rf_best.fit(X_train, y_train)\n",
    "\n",
    "print(\"Detailed classification report: Best Paramaters 1st Set\")\n",
    "y_best_pred = rf_best.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_best_pred))\n",
    "\n",
    "print(rf_best.oob_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the results above, we can see from the outofthebag score for the base rf model and hypertuned rf model, that the hypertuning resulting in an improvement in accuracy of roughly .5%. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will look at the importance of the variables in predicting the survival target variable \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Title_ Mrs</td>\n",
       "      <td>0.129654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Age_missing</td>\n",
       "      <td>0.090005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name_Length</td>\n",
       "      <td>0.088479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fam_Size</td>\n",
       "      <td>0.086771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.085799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0.079796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ticket_Length</td>\n",
       "      <td>0.042571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ticket_Char</td>\n",
       "      <td>0.041163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.037044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Title_ Mlle</td>\n",
       "      <td>0.036833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Title_ Ms</td>\n",
       "      <td>0.035035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0.030486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cabin_Number_missing</td>\n",
       "      <td>0.021836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.020992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.019713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Title_ Col</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.014844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Title_ Miss</td>\n",
       "      <td>0.010753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Ticket_First_Char_4</td>\n",
       "      <td>0.010356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Ticket_First_Char_3</td>\n",
       "      <td>0.010010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                variable  importance\n",
       "28            Title_ Mrs    0.129654\n",
       "8            Age_missing    0.090005\n",
       "3            Name_Length    0.088479\n",
       "4               Fam_Size    0.086771\n",
       "15            Embarked_Q    0.085799\n",
       "0                  SibSp    0.079796\n",
       "5          Ticket_Length    0.042571\n",
       "6            Ticket_Char    0.041163\n",
       "14              Sex_male    0.037044\n",
       "25           Title_ Mlle    0.036833\n",
       "29             Title_ Ms    0.035035\n",
       "1                  Parch    0.030486\n",
       "11  Cabin_Number_missing    0.021836\n",
       "12              Pclass_2    0.020992\n",
       "2                   Fare    0.019713\n",
       "17            Title_ Col    0.016300\n",
       "13              Pclass_3    0.014844\n",
       "24           Title_ Miss    0.010753\n",
       "35   Ticket_First_Char_4    0.010356\n",
       "34   Ticket_First_Char_3    0.010010"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(X_train.iloc[:, 1:].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf_best.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the above table, we can see the Titles of Men, Name Lengths, and Family Size have more importance in predicting the target survival category than other variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying predictor to Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import test data\n",
    "\n",
    "test_df = pd.read_csv(r'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Name titles for test data\n",
    "\n",
    "test_df['Title'] = test_df['Name'].str.split(r'[,.]').str.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Name lengths for test data\n",
    "\n",
    "test_df['Name_Length'] = test_df.Name.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sibling/spouse and parent/child data for test data\n",
    "\n",
    "test_df['Fam_Size'] = test_df.SibSp + test_df.Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Ticket lengths for test data \n",
    "\n",
    "test_df['Ticket_Length'] = test_df.Ticket.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add whether or not Ticket contains characters for test data\n",
    "\n",
    "test_df['Ticket_Char'] = test_df['Ticket'].str.isdigit()\n",
    "test_df['Ticket_Char'] = test_df.Ticket_Char.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add First character of tickets for test data\n",
    "\n",
    "test_df['Ticket_First_Char'] = test_df.Ticket.astype(str).str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Cabin deck designations for test data, and replace null strings as NaNs\n",
    "\n",
    "test_df['Cabin_Deck'] = test_df.Cabin.astype(str).str[0]\n",
    "test_df['Cabin_Deck'].replace('n',np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Cabin numbers for test data and replace null strings as NaNs\n",
    "\n",
    "test_df['Cabin_Number'] = test_df.Cabin.astype(str).str[1:]\n",
    "test_df['Cabin_Number'].replace('an',np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Account for lumped Cabin number values and convert strings to integers inplace\n",
    "\n",
    "test_df['Cabin_Number'] = test_df['Cabin_Number'].str.split(' ').str[0]\n",
    "test_df['Cabin_Number'] = pd.to_numeric(test_df['Cabin_Number'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Added columns to identify missing data points in variables in the test data set\n",
    "\n",
    "#Age\n",
    "test_df['Age_missing'] = (~test_df['Age'].isnull()).astype(int)\n",
    "\n",
    "#Cabin_Deck\n",
    "test_df['Cabin_Deck_missing'] = (~test_df['Cabin_Deck'].isnull()).astype(int)\n",
    "\n",
    "#Cabin_Number\n",
    "test_df['Cabin_Number_missing'] = (~test_df['Cabin_Number'].isnull()).astype(int)\n",
    "\n",
    "#Fare\n",
    "train_df['Fare'] = (~test_df['Fare'].isnull()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Pclass', 'Sex', 'Embarked', 'Title', 'Ticket_First_Char',\\n       'Cabin_Deck'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-e8bfc6b70070>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Pclass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ticket_First_Char'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cabin_Deck'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprefix_sep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\rboul\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    866\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be a list-like for parameter `columns`\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mdata_to_encode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[1;31m# validate prefixes and separator to avoid silently dropping cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\rboul\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\rboul\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1552\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1553\u001b[0m         )\n\u001b[0;32m   1554\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\rboul\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1638\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1639\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1641\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Pclass', 'Sex', 'Embarked', 'Title', 'Ticket_First_Char',\\n       'Cabin_Deck'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "test_df = pd.get_dummies(test_df, columns = ['Pclass', 'Sex', 'Embarked', 'Title', 'Ticket_First_Char', 'Cabin_Deck'],prefix_sep='_', drop_first = True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop PassengerID, Name, Ticket, Cabin columns\n",
    "\n",
    "test_df = test_df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute missing vlaues in test data, using same settings from train data imputer\n",
    "\n",
    "imputer = IterativeImputer(random_state=42)\n",
    "\n",
    "test_df_imputed = pd.DataFrame(imputer.fit_transform(test_df), columns = test_df.columns)\n",
    "\n",
    "test_df = test_df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding in the missing columns for predicting test data target variable that resulted from different categorical value encoding from .getdummies() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get missing columns in the training test\n",
    "missing_cols = set( train_df.columns ) - set( test_df.columns )\n",
    "# Add a missing column in test set with default value equal to 0\n",
    "for c in missing_cols:\n",
    "    test_df[c] = 0\n",
    "# Ensure the order of column in the test set is in the same order than in train set\n",
    "test_df = test_df[train_df.columns]\n",
    "\n",
    "#Drop extra Survived column from test data\n",
    "test_df = test_df.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict survival for test data set using the hypertuned rf model from earlier.\n",
    "\n",
    "test_df_predictions = pd.DataFrame(rf_best.predict(test_df), columns=['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived\n",
       "0         0.0\n",
       "1         1.0\n",
       "2         0.0\n",
       "3         0.0\n",
       "4         1.0\n",
       "..        ...\n",
       "413       0.0\n",
       "414       1.0\n",
       "415       0.0\n",
       "416       0.0\n",
       "417       1.0\n",
       "\n",
       "[418 rows x 1 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int32\n",
      "dtypes: int32(1), int64(1)\n",
      "memory usage: 5.0 KB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "predictions = pd.concat((test_df.iloc[:, 0], test_df_predictions.astype(int)), axis = 1)\n",
    "predictions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The line of code below is particularly important as Kaggle would rate the predictions wrong if the Survived value in not of int data type\n",
    "# submission.Survived = submission.Survived.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.to_csv('Random_Forest2.0_Results1.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
